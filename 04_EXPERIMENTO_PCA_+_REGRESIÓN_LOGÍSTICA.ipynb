{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EnVrtJIANPz",
        "outputId": "bdaaacf3-2830-4cb4-dd52-9cdc5e547a60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from opendatasets) (4.67.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (from opendatasets) (1.7.4.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from opendatasets) (8.3.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (6.3.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2025.11.12)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (3.11)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (0.5.1)\n",
            "Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n",
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: simoncorrearios\n",
            "Your Kaggle Key: ··········\n",
            "Downloading udea-ai-4-eng-20252-pruebas-saber-pro-colombia.zip to ./udea-ai-4-eng-20252-pruebas-saber-pro-colombia\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29.9M/29.9M [00:00<00:00, 1.30GB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Extracting archive ./udea-ai-4-eng-20252-pruebas-saber-pro-colombia/udea-ai-4-eng-20252-pruebas-saber-pro-colombia.zip to ./udea-ai-4-eng-20252-pruebas-saber-pro-colombia\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entrenando PCA + Regresión Logística...\n",
            "¡Entrenamiento completado!\n",
            "Generando predicciones...\n",
            "Archivo 'submission_pca_logreg.csv' generado.\n",
            "       ID RENDIMIENTO_GLOBAL\n",
            "0  550236               bajo\n",
            "1   98545         medio-alto\n",
            "2  499179               alto\n",
            "3  782980               bajo\n",
            "4  785185               bajo\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# 04 - EXPERIMENTO: PCA + REGRESIÓN LOGÍSTICA\n",
        "# ============================================================\n",
        "\n",
        "# 1. Importaciones\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.decomposition import PCA # Para reducción de dimensionalidad\n",
        "from sklearn.linear_model import LogisticRegression # Modelo lineal simple\n",
        "\n",
        "!pip install opendatasets\n",
        "import opendatasets as od\n",
        "\n",
        "# 2. Carga de Datos\n",
        "dataset_link=\"https://www.kaggle.com/competitions/udea-ai-4-eng-20252-pruebas-saber-pro-colombia/overview\"\n",
        "od.download(dataset_link)\n",
        "\n",
        "data_path = \"udea-ai-4-eng-20252-pruebas-saber-pro-colombia/\"\n",
        "train = pd.read_csv(data_path + \"train.csv\")\n",
        "test = pd.read_csv(data_path + \"test.csv\")\n",
        "\n",
        "test_ids = test['ID']\n",
        "\n",
        "# 3. Separación X / y\n",
        "target_col = 'RENDIMIENTO_GLOBAL'\n",
        "X = train.drop([target_col, 'ID'], axis=1)\n",
        "y = train[target_col]\n",
        "X_test = test.drop('ID', axis=1)\n",
        "\n",
        "# 4. Preprocesado (Igual que en la entrega anterior)\n",
        "numeric_features = X.select_dtypes(include=np.number).columns.tolist()\n",
        "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "if 'PERIODO_ACADEMICO' in numeric_features:\n",
        "    numeric_features.remove('PERIODO_ACADEMICO')\n",
        "    categorical_features.append('PERIODO_ACADEMICO')\n",
        "    X['PERIODO_ACADEMICO'] = X['PERIODO_ACADEMICO'].astype(str)\n",
        "    X_test['PERIODO_ACADEMICO'] = X_test['PERIODO_ACADEMICO'].astype(str)\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "# 5. Codificación del Target\n",
        "categories_order = [['bajo', 'medio-bajo', 'medio-alto', 'alto']]\n",
        "target_encoder = OrdinalEncoder(categories=categories_order)\n",
        "y_encoded = target_encoder.fit_transform(y.to_frame()).ravel()\n",
        "\n",
        "# 6. DEFINICIÓN DEL MODELO (AQUÍ ESTÁ LA DIFERENCIA)\n",
        "# Pipeline: Preprocesado -> PCA (Reducir a 100 dim) -> Regresión Logística\n",
        "model_pca = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('pca', PCA(n_components=100, random_state=42)),\n",
        "    ('classifier', LogisticRegression(max_iter=1000, random_state=42, solver='saga'))\n",
        "    # solver='saga' es bueno para datasets grandes\n",
        "])\n",
        "\n",
        "# 7. Entrenamiento\n",
        "print(\"Entrenando PCA + Regresión Logística...\")\n",
        "model_pca.fit(X, y_encoded)\n",
        "print(\"¡Entrenamiento completado!\")\n",
        "\n",
        "# 8. Predicción\n",
        "print(\"Generando predicciones...\")\n",
        "y_pred_encoded = model_pca.predict(X_test)\n",
        "\n",
        "# 9. Generar Submission\n",
        "y_pred_labels = target_encoder.inverse_transform(y_pred_encoded.reshape(-1, 1)).ravel()\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    'ID': test_ids,\n",
        "    'RENDIMIENTO_GLOBAL': y_pred_labels\n",
        "})\n",
        "\n",
        "submission.to_csv('submission_pca_logreg.csv', index=False)\n",
        "print(\"Archivo 'submission_pca_logreg.csv' generado.\")\n",
        "print(submission.head())"
      ]
    }
  ]
}