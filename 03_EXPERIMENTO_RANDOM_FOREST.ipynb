{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# 03 - EXPERIMENTO: RANDOM FOREST\n",
        "# ==========================================\n",
        "\n",
        "# 1. Configuración e Importaciones\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "!pip install opendatasets\n",
        "import opendatasets as od\n",
        "\n",
        "# 2. Carga de Datos\n",
        "dataset_link=\"https://www.kaggle.com/competitions/udea-ai-4-eng-20252-pruebas-saber-pro-colombia/overview\"\n",
        "od.download(dataset_link)\n",
        "\n",
        "data_path = \"udea-ai-4-eng-20252-pruebas-saber-pro-colombia/\"\n",
        "train = pd.read_csv(data_path + \"train.csv\")\n",
        "test = pd.read_csv(data_path + \"test.csv\")\n",
        "\n",
        "# Guardamos los IDs del test para el archivo de envío final\n",
        "test_ids = test['ID']\n",
        "\n",
        "# 3. Separación de Features y Target\n",
        "target_col = 'RENDIMIENTO_GLOBAL'\n",
        "\n",
        "# Preparamos X e y\n",
        "X = train.drop([target_col, 'ID'], axis=1)\n",
        "y = train[target_col]\n",
        "X_test = test.drop('ID', axis=1)\n",
        "\n",
        "# 4. Preprocesado (Pipeline de la entrega anterior)\n",
        "# Definimos listas de columnas\n",
        "numeric_features = X.select_dtypes(include=np.number).columns.tolist()\n",
        "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# PERIODO_ACADEMICO a texto\n",
        "if 'PERIODO_ACADEMICO' in numeric_features:\n",
        "    numeric_features.remove('PERIODO_ACADEMICO')\n",
        "    categorical_features.append('PERIODO_ACADEMICO')\n",
        "    X['PERIODO_ACADEMICO'] = X['PERIODO_ACADEMICO'].astype(str)\n",
        "    X_test['PERIODO_ACADEMICO'] = X_test['PERIODO_ACADEMICO'].astype(str)\n",
        "\n",
        "# Pipelines de transformación\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "# 5. Codificación del Target (Etiquetas)\n",
        "# Definimos el orden para que tenga sentido (ordinal)\n",
        "categories_order = [['bajo', 'medio-bajo', 'medio-alto', 'alto']]\n",
        "target_encoder = OrdinalEncoder(categories=categories_order)\n",
        "y_encoded = target_encoder.fit_transform(y.to_frame()).ravel() # .ravel() para hacerlo array 1D\n",
        "\n",
        "# 6. Definición del Modelo Completo (Pipeline + Modelo)\n",
        "# Usamos RandomForestClassifier. n_estimators=100 es un estándar sólido.\n",
        "model = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    # Cambios realizados:\n",
        "    # 1. n_estimators: Bajamos de 100 a 50 (mitad de tiempo)\n",
        "    # 2. max_depth: Limitamos la profundidad a 15 (evita que los árboles crezcan infinito y coman RAM)\n",
        "    # 3. max_features: 'sqrt' (es el default, pero nos aseguramos)\n",
        "    ('classifier', RandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        max_depth=25,\n",
        "        min_samples_leaf=10,\n",
        "        n_jobs=-1,\n",
        "        random_state=42\n",
        "    ))\n",
        "])\n",
        "\n",
        "# 7. Entrenamiento\n",
        "print(\"Entrenando el modelo (esto puede tardar unos minutos)...\")\n",
        "model.fit(X, y_encoded)\n",
        "print(\"¡Entrenamiento completado!\")\n",
        "\n",
        "# 8. Predicción sobre el Test Set\n",
        "print(\"Generando predicciones sobre test.csv...\")\n",
        "y_pred_encoded = model.predict(X_test)\n",
        "\n",
        "# 9. Decodificación y Generación del Submission\n",
        "# Importante: Kaggle espera las etiquetas de texto (bajo, alto, etc.), no números (0, 1, 2, 3)\n",
        "# Usamos inverse_transform para volver a texto\n",
        "y_pred_labels = target_encoder.inverse_transform(y_pred_encoded.reshape(-1, 1)).ravel()\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    'ID': test_ids,\n",
        "    'RENDIMIENTO_GLOBAL': y_pred_labels\n",
        "})\n",
        "\n",
        "# 10. Guardar archivo\n",
        "submission.to_csv('submission_rf.csv', index=False)\n",
        "print(\"Archivo 'submission_rf.csv' guardado exitosamente.\")\n",
        "print(submission.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXMGYx1dLNGf",
        "outputId": "8d846816-5742-47ce-a3c6-7157bedd5883"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from opendatasets) (4.67.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (from opendatasets) (1.7.4.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from opendatasets) (8.3.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (6.3.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2025.11.12)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (3.11)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (0.5.1)\n",
            "Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n",
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: simoncorrearios\n",
            "Your Kaggle Key: ··········\n",
            "Downloading udea-ai-4-eng-20252-pruebas-saber-pro-colombia.zip to ./udea-ai-4-eng-20252-pruebas-saber-pro-colombia\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29.9M/29.9M [00:00<00:00, 736MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Extracting archive ./udea-ai-4-eng-20252-pruebas-saber-pro-colombia/udea-ai-4-eng-20252-pruebas-saber-pro-colombia.zip to ./udea-ai-4-eng-20252-pruebas-saber-pro-colombia\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entrenando el modelo (esto puede tardar unos minutos)...\n",
            "¡Entrenamiento completado!\n",
            "Generando predicciones sobre test.csv...\n",
            "Archivo 'submission_rf.csv' guardado exitosamente.\n",
            "       ID RENDIMIENTO_GLOBAL\n",
            "0  550236               alto\n",
            "1   98545         medio-alto\n",
            "2  499179               alto\n",
            "3  782980               bajo\n",
            "4  785185               bajo\n"
          ]
        }
      ]
    }
  ]
}