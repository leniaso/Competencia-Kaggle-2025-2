{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBUEzM9KIwTB",
        "outputId": "51a1b02b-3c42-4237-cf25-55d316762880"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opendatasets in /usr/local/lib/python3.12/dist-packages (0.1.22)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from opendatasets) (4.67.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (from opendatasets) (1.7.4.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from opendatasets) (8.3.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (6.3.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2025.11.12)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (3.11)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (0.5.1)\n",
            "Skipping, found downloaded files in \"./udea-ai-4-eng-20252-pruebas-saber-pro-colombia\" (use force=True to force download)\n",
            "Transformando datos (manteniendo formato disperso para ahorrar RAM)...\n",
            "Dimensiones de X train: (692500, 1050)\n",
            "Tipo de dato: <class 'scipy.sparse._csr.csr_matrix'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entrenando Red Neuronal Mejorada...\n",
            "Epoch 1/30\n",
            "\u001b[1m4329/4329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 30ms/step - accuracy: 0.3956 - loss: 1.3026 - val_accuracy: 0.4321 - val_loss: 1.2013 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m4329/4329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 30ms/step - accuracy: 0.4318 - loss: 1.2036 - val_accuracy: 0.4381 - val_loss: 1.1949 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m4329/4329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 29ms/step - accuracy: 0.4383 - loss: 1.1933 - val_accuracy: 0.4383 - val_loss: 1.1910 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m4329/4329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 29ms/step - accuracy: 0.4428 - loss: 1.1876 - val_accuracy: 0.4426 - val_loss: 1.1865 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m4329/4329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 29ms/step - accuracy: 0.4434 - loss: 1.1842 - val_accuracy: 0.4418 - val_loss: 1.1864 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m4329/4329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.4467 - loss: 1.1798\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m4329/4329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 29ms/step - accuracy: 0.4467 - loss: 1.1798 - val_accuracy: 0.4421 - val_loss: 1.1877 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m4329/4329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 30ms/step - accuracy: 0.4507 - loss: 1.1723 - val_accuracy: 0.4449 - val_loss: 1.1832 - learning_rate: 5.0000e-04\n",
            "Epoch 8/30\n",
            "\u001b[1m4329/4329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 30ms/step - accuracy: 0.4554 - loss: 1.1675 - val_accuracy: 0.4437 - val_loss: 1.1844 - learning_rate: 5.0000e-04\n",
            "Epoch 9/30\n",
            "\u001b[1m4329/4329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.4560 - loss: 1.1646\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m4329/4329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 30ms/step - accuracy: 0.4560 - loss: 1.1646 - val_accuracy: 0.4443 - val_loss: 1.1847 - learning_rate: 5.0000e-04\n",
            "Epoch 10/30\n",
            "\u001b[1m4329/4329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 30ms/step - accuracy: 0.4605 - loss: 1.1585 - val_accuracy: 0.4427 - val_loss: 1.1858 - learning_rate: 2.5000e-04\n",
            "Epoch 11/30\n",
            "\u001b[1m4329/4329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.4619 - loss: 1.1553\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m4329/4329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 30ms/step - accuracy: 0.4619 - loss: 1.1553 - val_accuracy: 0.4427 - val_loss: 1.1868 - learning_rate: 2.5000e-04\n",
            "Epoch 12/30\n",
            "\u001b[1m4329/4329\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 30ms/step - accuracy: 0.4637 - loss: 1.1521 - val_accuracy: 0.4429 - val_loss: 1.1874 - learning_rate: 1.2500e-04\n",
            "Epoch 12: early stopping\n",
            "Restoring model weights from the end of the best epoch: 7.\n",
            "Generando predicciones...\n",
            "\u001b[1m9275/9275\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 6ms/step\n",
            "Archivo 'submission.csv' generado exitosamente.\n",
            "       ID RENDIMIENTO_GLOBAL\n",
            "0  550236               bajo\n",
            "1   98545         medio-alto\n",
            "2  499179               alto\n",
            "3  782980               bajo\n",
            "4  785185               bajo\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# 99 - modelo solución\n",
        "# ============================================================\n",
        "\n",
        "# 1. Importaciones\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "!pip install opendatasets\n",
        "import opendatasets as od\n",
        "import scipy\n",
        "\n",
        "# 2. Carga\n",
        "dataset_link=\"https://www.kaggle.com/competitions/udea-ai-4-eng-20252-pruebas-saber-pro-colombia/overview\"\n",
        "od.download(dataset_link)\n",
        "\n",
        "data_path = \"udea-ai-4-eng-20252-pruebas-saber-pro-colombia/\"\n",
        "train = pd.read_csv(data_path + \"train.csv\")\n",
        "test = pd.read_csv(data_path + \"test.csv\")\n",
        "test_ids = test['ID']\n",
        "\n",
        "target_col = 'RENDIMIENTO_GLOBAL'\n",
        "X = train.drop([target_col, 'ID'], axis=1)\n",
        "y = train[target_col]\n",
        "X_test = test.drop('ID', axis=1)\n",
        "\n",
        "# 3. Configuración del Preprocesador\n",
        "numeric_features = X.select_dtypes(include=np.number).columns.tolist()\n",
        "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "if 'PERIODO_ACADEMICO' in numeric_features:\n",
        "    numeric_features.remove('PERIODO_ACADEMICO')\n",
        "    categorical_features.append('PERIODO_ACADEMICO')\n",
        "    X['PERIODO_ACADEMICO'] = X['PERIODO_ACADEMICO'].astype(str)\n",
        "    X_test['PERIODO_ACADEMICO'] = X_test['PERIODO_ACADEMICO'].astype(str)\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    # Sparse=True es el default, ahorra memoria\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=True))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "# 4. PREPROCESADO MANUAL (SIN .toarray())\n",
        "print(\"Transformando datos (manteniendo formato disperso para ahorrar RAM)...\")\n",
        "\n",
        "# fit_transform devuelve una matriz 'sparse' (comprimida)\n",
        "X_processed = preprocessor.fit_transform(X)\n",
        "X_test_processed = preprocessor.transform(X_test)\n",
        "\n",
        "# Ordenar los índices hace que Keras lea la matriz más rápido\n",
        "X_processed.sort_indices()\n",
        "X_test_processed.sort_indices()\n",
        "\n",
        "print(f\"Dimensiones de X train: {X_processed.shape}\")\n",
        "print(\"Tipo de dato:\", type(X_processed)) # Verás que es scipy.sparse.csr_matrix\n",
        "\n",
        "# 5. Codificación del Target\n",
        "categories_order = [['bajo', 'medio-bajo', 'medio-alto', 'alto']]\n",
        "target_encoder = OrdinalEncoder(categories=categories_order)\n",
        "y_int = target_encoder.fit_transform(y.to_frame())\n",
        "y_categorical = to_categorical(y_int)\n",
        "\n",
        "# 6. DEFINICIÓN DE LA RED NEURONAL\n",
        "input_dim = X_processed.shape[1]\n",
        "num_classes = 4\n",
        "\n",
        "model_nn = Sequential([\n",
        "    # --- Capa 1: Entrada Grande ---\n",
        "    # Usamos 512 neuronas para capturar más detalles de las 1000 columnas\n",
        "    Dense(512, activation='relu', input_shape=(input_dim,)),\n",
        "    BatchNormalization(), # Normaliza los datos dentro de la red\n",
        "    Dropout(0.3),         # Apaga el 30% para evitar memorizar\n",
        "\n",
        "    # --- Capa 2: Procesamiento Intermedio ---\n",
        "    Dense(256, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    # --- Capa 3: Refinamiento ---\n",
        "    Dense(128, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.2),\n",
        "\n",
        "    # --- Capa de Salida ---\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Usamos un learning rate un poco más bajo para ser más precisos\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "model_nn.compile(optimizer=opt,\n",
        "                 loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy'])\n",
        "\n",
        "# 7. ENTRENAMIENTO INTELIGENTE (CALLBACKS)\n",
        "# Definimos \"vigilantes\" para el entrenamiento\n",
        "callbacks_list = [\n",
        "    # Si la 'val_loss' no mejora en 5 épocas, para de entrenar.\n",
        "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1),\n",
        "\n",
        "    # Si se estanca, reduce la velocidad de aprendizaje (learning rate) para afinar.\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1)\n",
        "]\n",
        "\n",
        "print(\"Entrenando Red Neuronal Mejorada...\")\n",
        "# Aumentamos epochs a 30, pero el EarlyStopping lo detendrá antes si es necesario\n",
        "history = model_nn.fit(\n",
        "    X_processed,\n",
        "    y_categorical,\n",
        "    epochs=30,           # Le damos más tiempo\n",
        "    batch_size=128,      # Batch más grande para que sea estable y rápido\n",
        "    validation_split=0.2,\n",
        "    callbacks=callbacks_list # Añadimos los vigilantes\n",
        ")\n",
        "\n",
        "# 8. Predicción\n",
        "print(\"Generando predicciones...\")\n",
        "# Keras también acepta matrices dispersas en .predict()\n",
        "y_pred_probs = model_nn.predict(X_test_processed)\n",
        "y_pred_int = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "# 9. Generar Submission\n",
        "y_pred_labels = target_encoder.inverse_transform(y_pred_int.reshape(-1, 1)).ravel()\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    'ID': test_ids,\n",
        "    'RENDIMIENTO_GLOBAL': y_pred_labels\n",
        "})\n",
        "\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "print(\"Archivo 'submission.csv' generado exitosamente.\")\n",
        "print(submission.head())"
      ]
    }
  ]
}